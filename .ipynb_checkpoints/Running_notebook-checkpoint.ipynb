{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a58dfb4-06a5-403a-a413-f08f4c8deb1f",
   "metadata": {},
   "source": [
    "# In the US from 1999 to 2015, were legal teams featuring greater proportions of female lawyers more or less likely to forum shop in patent law cases? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f9410-ddb5-4622-aec3-1fe99c485f2f",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee129d7-44c1-44c1-88a9-1a5b1e78292d",
   "metadata": {},
   "source": [
    "Brief introduction\n",
    "Write a brief introduction of your project (two to four para-\n",
    "graphs), the source of the data, and the important background necessary to un-\n",
    "derstand your project (Keep it short. You will complete it over time). An outsider\n",
    "should be able to understand what you are trying to do in this project. You should\n",
    "state your data and its source, discuss your research question, and briefly mention\n",
    "your findings. You should have at least five citations with one of them as your\n",
    "main paper, and that paper should be the closest paper to your work. The citation\n",
    "should show up in your references section as well in APA or Chicago style"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8937ed4d-4877-4d45-9e38-ec364d9a8499",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f155002-12fd-45c2-9cc5-334a58400c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALASKA AND HAWAII: https://medium.com/@alex_44314/use-python-geopandas-to-make-a-us-map-with-alaska-and-hawaii-39a9f5c222c6 \n",
    "\n",
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import gc\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import re\n",
    "\n",
    "# make head display all columns instead of truncting\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01bced-6ab4-4e81-8024-fd05dae8d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to search up names to insert into gender_nocode dataset\n",
    "# gender = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/wgnd_2_0_name-gender-code.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a2e965-f8b6-4f52-95ee-6ad76b4aaf30",
   "metadata": {},
   "source": [
    "Cases data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da4d321-1b1d-4776-9aa1-a1ed71319f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call cases data to jupyter notebook\n",
    "cases = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/cases.csv\")\n",
    "cases = cases.sort_values(\"case_name\", ascending=True)\n",
    "\n",
    "### prepare the cases dataset for merging\n",
    "\n",
    "# create year variable\n",
    "cases[\"year_filed\"] = cases[\"case_number\"].str.split(\":\").str[1].str[:2].astype(float)\n",
    "cases.loc[cases.year_filed > 17, \"year_filed\"] = cases[\"year_filed\"] + 1900\n",
    "cases.loc[cases.year_filed < 17, \"year_filed\"] = cases[\"year_filed\"] + 2000\n",
    "cases[\"year_filed\"] = cases[\"year_filed\"].fillna(0).astype(float)\n",
    "\n",
    "# these observations don't have a properly formatted case number\n",
    "cases = cases.drop(index=[0, 1885, 1886])\n",
    "\n",
    "# create case order variable (indicates 1 more than the number of cases that the court received before that case in that year)\n",
    "cases[\"case_order\"] = cases[\"case_number\"].str.split(\":\").str[1]\n",
    "cases[\"case_order\"] = cases[\"case_order\"].str.split(\"-\").str[2].astype(float)\n",
    "\n",
    "# create variable showing the courthouse within the district that received the case\n",
    "cases[\"courthouse\"] = cases[\"case_number\"].str.split(\":\").str[0]\n",
    "\n",
    "# standardize the court name variable so that it can be merged\n",
    "cases[\"court_name\"] = cases[\"court_name\"].str.title()\n",
    "\n",
    "# adjust these two specific values\n",
    "cases[\"court_name\"] = cases[\"court_name\"].str.replace(\"U.S. District Court (Spokane)\", \"Eastern District Of Washington\")\n",
    "cases[\"court_name\"] = cases[\"court_name\"].str.replace(\"U.S. District Court (7)\", \"7th Court of Appeals\")\n",
    "\n",
    "# create region variable\n",
    "cases.loc[cases.court_name.str.contains(\"Eastern\"), \"court_region\"] = \"Eastern\"\n",
    "cases.loc[cases.court_name.str.contains(\"Southern\"), \"court_region\"] = \"Southern\"\n",
    "cases.loc[cases.court_name.str.contains(\"Western\"), \"court_region\"] = \"Western\"\n",
    "cases.loc[cases.court_name.str.contains(\"Northern\"), \"court_region\"] = \"Northern\"\n",
    "cases[\"court_region\"] = cases[\"court_region\"].fillna(\"None\")\n",
    "\n",
    "# create state variable\n",
    "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District Of Columbia\", \"Delaware\", \n",
    "          \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \n",
    "          \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \n",
    "          \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \n",
    "          \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \n",
    "          \"Wisconsin\", \"West Virginia\", \"Wyoming\", \"7th\"]\n",
    "\n",
    "for state in state_names:\n",
    "    cases.loc[cases.court_name.str.contains(state), \"court_state\"] = state\n",
    "\n",
    "# process demand variable to get rid of non-numeric values\n",
    "cases[\"demand\"] = cases[\"demand\"].astype(str)\n",
    "cases.loc[False == cases.demand.str.strip().str.isalpha(), \"demand_num\"] = cases[\"demand\"]\n",
    "cases[\"demand_num\"] = cases[\"demand_num\"].str.replace(\"$\", \"\")\n",
    "cases[\"demand_num\"] = cases[\"demand_num\"].str.replace(\",\", \"\")\n",
    "cases[\"demand_num\"] = cases[\"demand_num\"].astype(float)\n",
    "\n",
    "cases.loc[cases.demand.str.strip().str.isalpha(), \"demand_party\"] = cases[\"demand\"]\n",
    "cases[\"demand_party\"] = cases[\"demand_party\"].astype(str)\n",
    "cases[\"demand_party\"] = cases[\"demand_party\"].str.replace(\"p\", \"Plaintiff\")\n",
    "cases.loc[cases.demand_party == \"P\", \"demand_party\"] = str(\"Plaintiff\")\n",
    "cases.loc[cases.demand_party == \"y\", \"demand_party\"] = np.nan\n",
    "cases.loc[cases.demand_party == \"Y\", \"demand_party\"] = np.nan\n",
    "cases.loc[cases.demand_party == \"nan\", \"demand_party\"] = np.nan\n",
    "# check you only have the values you desire\n",
    "cases[\"demand_party\"].unique()\n",
    "\n",
    "# check for missing values\n",
    "# cases.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d64020-666b-4178-860e-eb93a6eee784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call pacer_cases data to jupyter notebook\n",
    "pacer_cases = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/pacer_cases.csv\")\n",
    "pacer_cases = pacer_cases.sort_values(\"case_name\", ascending=True)\n",
    "\n",
    "# prepare the pacer_cases dataset for merging\n",
    "\n",
    "# construct year variable\n",
    "pacer_cases[\"year_filed\"] = pacer_cases[\"case_number\"].str.split(\":\").str[1].str[:4]\n",
    "pacer_cases.loc[False == pacer_cases[\"year_filed\"].str.isnumeric(), \"year_filed\"] = pacer_cases[\"year_filed\"].str[:2].astype(float) + 2000\n",
    "pacer_cases[\"year_filed\"] = pacer_cases[\"year_filed\"].fillna(0).astype(int)\n",
    "# NOTE: 0 indicates NaN, 56 values\n",
    "\n",
    "# construct case order (-1 indicates the number of cases that the court received before that case in that year)\n",
    "pacer_cases[\"case_order\"] = pacer_cases[\"case_number\"].str.split(\":\").str[1]\n",
    "pacer_cases[\"case_order\"] = pacer_cases[\"case_order\"].str.split(\"-\").str[2]\n",
    "pacer_cases.loc[False == pacer_cases[\"case_order\"].str.isnumeric(), \"case_order\"] = pacer_cases[\"case_order\"].str.split(\".\").str[0]\n",
    "pacer_cases.loc[False == pacer_cases[\"case_order\"].str.isnumeric(), \"case_order\"] = pacer_cases[\"case_order\"].str[:5]\n",
    "pacer_cases[\"case_order\"] = pacer_cases[\"case_order\"].astype(float)\n",
    "\n",
    "# indicates the courthouse within the district that received the case\n",
    "pacer_cases[\"courthouse\"] = pacer_cases[\"case_number\"].str.split(\":\").str[0]\n",
    "\n",
    "# standardize the court name variable so that it can be merged\n",
    "pacer_cases[\"court_name\"] = pacer_cases[\"court_name\"].str.title()\n",
    "pacer_cases[\"court_name\"] = pacer_cases[\"court_name\"].str.split(\"(\").str[0]\n",
    "\n",
    "# create region variable\n",
    "pacer_cases.loc[pacer_cases.court_name.str.contains(\"Eastern\"), \"court_region\"] = \"Eastern\"\n",
    "pacer_cases.loc[pacer_cases.court_name.str.contains(\"Southern\"), \"court_region\"] = \"Southern\"\n",
    "pacer_cases.loc[pacer_cases.court_name.str.contains(\"Western\"), \"court_region\"] = \"Western\"\n",
    "pacer_cases.loc[pacer_cases.court_name.str.contains(\"Northern\"), \"court_region\"] = \"Northern\"\n",
    "pacer_cases[\"court_region\"] = pacer_cases[\"court_region\"].fillna(\"None\")\n",
    "\n",
    "# create state variable\n",
    "state_names = [\"Alaska\", \"Alabama\", \"Arkansas\", \"American Samoa\", \"Arizona\", \"California\", \"Colorado\", \"Connecticut\", \"District Of Columbia\", \"Delaware\", \n",
    "          \"Florida\", \"Georgia\", \"Guam\", \"Hawaii\", \"Iowa\", \"Idaho\", \"Illinois\", \"Indiana\", \"Kansas\", \"Kentucky\", \"Louisiana\", \"Massachusetts\", \n",
    "          \"Maryland\", \"Maine\", \"Michigan\", \"Minnesota\", \"Missouri\", \"Mississippi\", \"Montana\", \"North Carolina\", \"North Dakota\", \"Nebraska\", \n",
    "          \"New Hampshire\", \"New Jersey\", \"New Mexico\", \"Nevada\", \"New York\", \"Ohio\", \"Oklahoma\", \"Oregon\", \"Pennsylvania\", \"Puerto Rico\", \n",
    "          \"Rhode Island\", \"South Carolina\", \"South Dakota\", \"Tennessee\", \"Texas\", \"Utah\", \"Virginia\", \"Virgin Islands\", \"Vermont\", \"Washington\", \n",
    "          \"Wisconsin\", \"West Virginia\", \"Wyoming\", \"7th\"]\n",
    "\n",
    "for state in state_names:\n",
    "    pacer_cases.loc[pacer_cases.court_name.str.contains(state), \"court_state\"] = state\n",
    "\n",
    "# check for missing values\n",
    "# pacer_cases.isna().sum()\n",
    "# pacer_cases[pacer_cases[\"case_order\"].isna()]\n",
    "# for 76 rows, the pacer dataset doesn't have a valid case number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283d8bd3-a4b4-42a9-948c-3ba283297e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge\n",
    "m_cases = pd.merge(cases, pacer_cases, on=[\"year_filed\", \"case_order\", \"courthouse\", \"court_region\", \"court_state\"], how=\"left\")\n",
    "\n",
    "# fill in missing values from the cases dataset using the pacer_cases dataset\n",
    "m_cases[\"case_name_x\"] = m_cases[\"case_name_x\"].fillna(m_cases[\"case_name_y\"])\n",
    "m_cases[\"date_filed_x\"] = m_cases[\"date_filed_x\"].fillna(m_cases[\"date_filed_y\"])\n",
    "m_cases[\"date_closed_x\"] = m_cases[\"date_closed_x\"].fillna(m_cases[\"date_filed_y\"])\n",
    "\n",
    "# check for missing values\n",
    "m_cases.isna().sum()\n",
    "\n",
    "# group dataset by whether the year is before or after 1999\n",
    "m_cases.loc[m_cases.year_filed >= 1999, \"post_99\"] = 1\n",
    "m_cases.loc[m_cases.year_filed < 1999, \"post_99\"] = 0\n",
    "grouped_cases = m_cases.groupby(by=\"post_99\")\n",
    "\n",
    "# convert dates to date format\n",
    "m_cases[\"date_filed\"] = pd.to_datetime(m_cases[\"date_filed_x\"])\n",
    "m_cases[\"date_closed\"] = pd.to_datetime(m_cases[\"date_closed_x\"])\n",
    "m_cases[\"date_last_filed\"] = pd.to_datetime(m_cases[\"date_last_filed\"])\n",
    "\n",
    "# drop superfluous variables\n",
    "m_cases = m_cases.drop(columns=[\"date_filed_x\", \"date_closed_x\", \"case_name_y\", \"court_name_y\", \"date_closed_y\", \"case_number_y\", \n",
    "                                \"pacer_id_y\", \"date_filed_y\"])\n",
    "\n",
    "# make a subset of the dataset with just the cases since 1999\n",
    "cases_99 = m_cases.drop(m_cases[m_cases[\"post_99\"] != 1].index)\n",
    "\n",
    "# list(cases_99[\"case_cause\"].unique())\n",
    "\n",
    "# create a binary variable indicating whether a case involves patent infringement\n",
    "cases_99[\"case_cause\"] = cases_99[\"case_cause\"].str.lower()\n",
    "cases_99[\"case_cause\"] = cases_99[\"case_cause\"].str.strip()\n",
    "cases_99.loc[cases_99.case_cause.str.contains(\"infringement of patent\", na=False), \"patent_infringement\"] = 1\n",
    "cases_99.loc[cases_99.case_cause.str.contains(\"patent infringement\", na=False), \"patent_infringement\"] = 1\n",
    "cases_99[\"patent_infringement\"] = cases_99[\"patent_infringement\"].fillna(0)\n",
    "\n",
    "list(cases_99[\"case_cause\"].unique())\n",
    "cases_99[\"patent_infringement\"].value_counts()\n",
    "\n",
    "# delete superfluous datasets\n",
    "del [m_cases, cases, pacer_cases]\n",
    "gc.collect()\n",
    "m_cases = pd.DataFrame()\n",
    "cases = pd.DataFrame()\n",
    "pacer_cases = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7948aea-6ee6-4ea0-ab87-d938210bf574",
   "metadata": {},
   "source": [
    "Attorneys Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa0b6e-b242-4014-b67b-f00a05ff34c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# call data to jupyter notebook\n",
    "attorneys = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/attorneys.csv\")\n",
    "gender = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/wgnd_2_0_name-gender_nocode.csv\")\n",
    "\n",
    "# fill (See above for address) using above\n",
    "attorneys[\"contactinfo\"] = attorneys[\"contactinfo\"].fillna(0)\n",
    "attorneys[\"contactinfo\"] = attorneys[\"contactinfo\"].str.strip()\n",
    "attorneys[\"contactinfo\"] = attorneys[\"contactinfo\"].replace('(See above for address)', np.nan)\n",
    "attorneys[\"contactinfo\"] = attorneys[\"contactinfo\"].ffill()\n",
    "\n",
    "attorneys[\"zip\"] = attorneys[\"contactinfo\"].str.extract(r\"(, [a-zA-Z][a-zA-Z] \\d\\d\\d\\d\\d)\")\n",
    "attorneys[\"zip\"] = attorneys[\"zip\"].str[5:]\n",
    "attorneys.head(40)\n",
    "attorneys[attorneys[\"zip\"].isna()].head(30)\n",
    "attorneys.isna().sum()\n",
    "\n",
    "# collapse dataset so that there's only one entry per attorney per case\n",
    "attorneys = attorneys.groupby([\"case_row_id\", \"name\"]).agg(\"first\")\n",
    "attorneys = attorneys.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ca7c1f-ac3d-489f-b3d8-5a51eab7f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract firm name\n",
    "attorneys[\"firm\"] = attorneys[\"contactinfo\"].str.split(\";\").str[0]\n",
    "\n",
    "# create a 100 row sample\n",
    "# sample_att = attorneys.sample(n=100)\n",
    "\n",
    "# examine the sample\n",
    "# pd.options.display.max_rows = 100\n",
    "# sample_att[[\"name\", \"contactinfo\", \"firm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82e0e6-c695-4b2b-af25-4786526b6595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable w first name\n",
    "attorneys[\"first_name\"] = attorneys[\"name\"].str.split().str[0].str.lower().astype(str)\n",
    "\n",
    "# merge with gender dataset, drop the dataset\n",
    "attorneys = attorneys.merge(gender, left_on=\"first_name\", right_on=\"name\", how=\"left\")\n",
    "del [gender]\n",
    "gc.collect()\n",
    "gender = pd.DataFrame()\n",
    "\n",
    "# attorneys.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03f2432-7a31-4419-abcc-542e6b0e4690",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_attorneys = attorneys[attorneys[\"gender\"].isna()]\n",
    "missing_attorneys = missing_attorneys[missing_attorneys[\"name_x\"].isna() == False]\n",
    "\n",
    "# merge with dataset with gender names for US\n",
    "gender = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/wgnd_2_0_name-gender-code_US_likely.csv\")\n",
    "missing_attorneys = missing_attorneys.merge(gender, left_on=\"first_name\", right_on=\"name\",how=\"left\")\n",
    "\n",
    "# drop variables so you can concat the missing_attorneys dataset with the attorneys dataset\n",
    "missing_attorneys = missing_attorneys.drop([\"name_y\", \"gender_x\"], axis= 1)\n",
    "missing_attorneys = missing_attorneys.rename(columns={\"gender_y\": \"gender\"})\n",
    "\n",
    "still_missing = missing_attorneys[missing_attorneys[\"gender\"].isna()== True]\n",
    "still_missing.to_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/still_missing_attorneys.csv\", index=False)\n",
    "# processed these names using https://genderize.io/tools/csv\n",
    "\n",
    "missing_attorneys = missing_attorneys[missing_attorneys[\"gender\"].isna()== False]\n",
    "# missing_attorneys.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f72cdf-9770-46fb-9eed-1129d8934cf7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop missing values from the attorneys dataset, add back the missing_attorneys\n",
    "attorneys = attorneys[attorneys[\"gender\"].isna() == False]\n",
    "attorneys = attorneys.rename(columns={\"name_y\": \"name\"})\n",
    "attorneys = pd.concat([attorneys, missing_attorneys], axis = 0)\n",
    "\n",
    "del [missing_attorneys]\n",
    "gc.collect()\n",
    "missing_attorneys = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f7d56-1664-408c-a8c4-5ac42ebc2db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add back the still_missing_attorneys\n",
    "still_missing = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/still_missing_attorneys_genderized_copy.csv\")\n",
    "\n",
    "still_missing.loc[still_missing.gender == \"male\", \"gender\"] = \"M\"\n",
    "still_missing.loc[still_missing.gender == \"female\", \"gender\"] = \"F\"\n",
    "still_missing.replace(\"unknown\", np.nan)\n",
    "\n",
    "# still_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552f516-044c-48d7-a697-98439b32a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "attorneys = pd.concat([attorneys, still_missing], axis=0)\n",
    "\n",
    "attorneys.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "# attorneys.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9f938-46b8-44fa-9f60-f5a7345b561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to see the possible values for party type\n",
    "# list(attorneys[\"party_type\"].unique())\n",
    "\n",
    "# list(attorneys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f19871c-df50-4757-8c48-2987801a9bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label each attorney either defendent, plantiff, or other\n",
    "list(attorneys[\"party_type\"].unique())\n",
    "attorneys[\"party_type\"] = attorneys[\"party_type\"].str.lower()\n",
    "\n",
    "attorneys.loc[attorneys.party_type.str.contains(\"defendant\"), \"defendant\"] = 1\n",
    "attorneys.loc[attorneys.party_type.str.contains(\"respondent\"), \"defendant\"] = 1\n",
    "attorneys.loc[attorneys.party_type.str.contains(\"counter claimant\"), \"defendant\"] = 1\n",
    "attorneys.loc[attorneys.party_type.str.contains(\"dft\"), \"defendant\"] = 1\n",
    "attorneys.loc[attorneys.party_type.str.contains(\"plaintiff\"), \"plaintiff\"] = 1\n",
    "\n",
    "attorneys.loc[attorneys.defendant.isna(), \"other\"] = 1\n",
    "attorneys.loc[attorneys.plaintiff.isna() == False, \"other\"] = 0\n",
    "\n",
    "# create gendered variables for each attorney category\n",
    "attorneys.loc[(attorneys[\"defendant\"] == 1)&(attorneys[\"gender\"] == \"M\"), \"defendant_M\"] = 1\n",
    "attorneys.loc[(attorneys[\"defendant\"] == 1)&(attorneys[\"gender\"] == \"F\"), \"defendant_F\"] = 1\n",
    "attorneys.loc[(attorneys[\"plaintiff\"] == 1)&(attorneys[\"gender\"] == \"M\"), \"plaintiff_M\"] = 1\n",
    "attorneys.loc[(attorneys[\"plaintiff\"] == 1)&(attorneys[\"gender\"] == \"F\"), \"plaintiff_F\"] = 1\n",
    "attorneys.loc[(attorneys[\"other\"] == 1)&(attorneys[\"gender\"] == \"M\"), \"other_M\"] = 1\n",
    "attorneys.loc[(attorneys[\"other\"] == 1)&(attorneys[\"gender\"] == \"F\"), \"other_F\"] = 1\n",
    "\n",
    "attorneys.loc[attorneys[\"gender\"] == \"M\", \"male\"] = 1\n",
    "attorneys.loc[attorneys[\"gender\"] == \"F\", \"female\"] = 1\n",
    "attorneys[\"total\"] = 1\n",
    "\n",
    "attorneys[['defendant', 'plaintiff', 'other', 'defendant_M', 'defendant_F', 'plaintiff_M', 'plaintiff_F','other_M',  'other_F', 'male', \n",
    "           'female']] = attorneys[['defendant', 'plaintiff', 'other', 'defendant_M', 'defendant_F', 'plaintiff_M', 'plaintiff_F','other_M', \n",
    "                                   'other_F', 'male', 'female']].fillna(value=0)\n",
    "\n",
    "# attorneys.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6378cf51-fdcf-43c1-b2b6-cc78d477d007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete unnecessary columns, then try aggregating\n",
    "c_attorneys = attorneys.drop(columns=[\"name_x\", \"case_number\", 'party_row_count', 'party_type', 'attorney_row_count', 'contactinfo', 'position', 'zip', \n",
    "                                      'firm', 'first_name', \"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ceabe-0530-48a2-8c62-3409759f5960",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(c_attorneys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563c246-b3be-4151-af37-1a730458d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate to create one row per case\n",
    "c_attorneys = c_attorneys.groupby(\"case_row_id\").agg({'defendant': \"sum\",\n",
    " 'plaintiff': \"sum\",\n",
    " 'other': \"sum\",\n",
    " 'defendant_M': \"sum\",\n",
    " 'defendant_F': \"sum\",\n",
    " 'plaintiff_M': \"sum\",\n",
    " 'plaintiff_F': \"sum\",\n",
    " 'other_M': \"sum\",\n",
    " 'other_F': \"sum\",\n",
    " 'male': \"sum\",\n",
    " 'female': \"sum\",\n",
    " 'total': \"sum\"})\n",
    "\n",
    "c_attorneys = c_attorneys.fillna(0)\n",
    "c_attorneys.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9999072-a2a3-4d21-8952-fd951db330c4",
   "metadata": {},
   "source": [
    "Documents data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccda7c-2d82-4712-aebf-6a9e2025f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call data to jupyter notebook\n",
    "documents = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/documents.csv\", low_memory=False)\n",
    "\n",
    "# clean\n",
    "documents[\"number_docs\"] = 1\n",
    "doc_agg = documents.groupby(\"case_row_id\").agg(\"sum\")\n",
    "\n",
    "# doc_agg.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67222ef1-af96-4e71-b167-c1ed01008494",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_agg = doc_agg.drop(doc_agg.iloc[:, 0:8], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3399229d-8f12-46f6-a43b-c93d32590d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use for code trying to see types of documents\n",
    "documents.loc[documents['long_description'].str.contains(r\"\\bsettle\\b\", na=False, case=False), \"settled\"] = 1\n",
    "# documents[documents[\"settled\"] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28aa83f-59cb-4296-a827-743b9cff8221",
   "metadata": {},
   "source": [
    "Names data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b10b46-a358-4f4e-87e8-1ee77f50a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# call data to jupyter notebook\n",
    "names = pd.read_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/names.csv\")\n",
    "# names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84e79c-baa8-45b1-8029-3302ee4e6ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view duplicates\n",
    "# names[names.duplicated(subset=['case_row_id','name'], keep=False)].sort_values(by=[\"name\", \"case_row_id\"], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e072a8af-3c85-40d6-9f56-d429d4e270d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it appears that the party_row_count is a unique identifer of a party in a case, and the name column includes information other than names\n",
    "# names[names.duplicated(subset=['party_row_count'], keep=False)].sort_values(\"party_row_count\", ascending=True).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de8ed6-d0cd-4294-9d74-0ab320de41b5",
   "metadata": {},
   "source": [
    "## Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0083fa5-2bc0-45e0-bd4e-c0b275772d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to create dataframe with one row per case\n",
    "df_cases = cases_99.merge(c_attorneys, on=\"case_row_id\", how=\"left\")\n",
    "df_cases = df_cases.merge(doc_agg, on=\"case_row_id\", how=\"left\")\n",
    "df_cases.isna().sum()\n",
    "\n",
    "df_cases.drop(columns=[\"pacer_id_x\", \"assigned_to\", \"referred_to\", \"case_cause\", \"jurisdictional_basis\", \"jury_demand\", \"lead_case\", \"related_case\", \n",
    "                       \"settlement\", \"date_last_filed\", \"demand_num\", \"demand\", \"demand_party\", \"court_code\", \"post_99\", \"date_filed\", \"date_closed\"], inplace=True) \n",
    "\n",
    "\n",
    "\n",
    "df_cases.sort_values(by=[\"case_row_id\"], inplace=True)\n",
    "\n",
    "df_cases = df_cases.rename(columns={\"case_number_x\": \"case_number\",\n",
    "                                \"case_name_x\": \"case_name\",\n",
    "                                \"court_name_x\": \"court_name\"\n",
    "                               })\n",
    "\n",
    "# df_cases.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9142d82-5ce6-4ec1-8eed-dfe00b375051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge to create df with one row per attorney\n",
    "df_att = attorneys.merge(df_cases, on=\"case_row_id\", how=\"inner\")\n",
    "# df_att = df_att.merge(doc_agg, on=\"case_row_id\", how=\"left\")\n",
    "df_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba17c73-5bc2-4d98-9f94-157e05991c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create inhouse attorney dataset\n",
    "\n",
    "df_att.drop(columns=[\"total_x\", \"case_number_y\", \"party_row_count\"], inplace=True) \n",
    "\n",
    "# rename columns to ready for merging\n",
    "df_att = df_att.rename(columns={\"case_number_x\": \"case_number\",\n",
    "                        \"name_x\": \"name_attorney\",\n",
    "                        \"defendant_x\": \"defendant\",\n",
    "                        \"plaintiff_x\": \"plaintiff\",\n",
    "                        \"other_x\": \"other\",\n",
    "                        \"defendant_M_x\": \"defendant_M\",\n",
    "                        \"defendant_F_x\": \"defendant_F\",\n",
    "                        \"plaintiff_M_x\": \"plaintiff_M\",\t\n",
    "                        \"plaintiff_F_x\": \"plaintiff_F\",\n",
    "                        \"other_M_x\": \"other_M\",\n",
    "                        \"other_F_x\": \"other_F\",\n",
    "                        \"male_x\": \"male\",\t\n",
    "                        \"female_x\": \"female\",\t\t\n",
    "                        \"defendant_y\": \"tot_def\",\n",
    "                        \"plaintiff_y\": \"tot_plain\",\n",
    "                        \"witness_y\": \"tot_wit\",\n",
    "                        \"other_y\": \"tot_other\",\n",
    "                        \"defendant_M_y\": \"tot_def_M\",\n",
    "                        \"defendant_F_y\": \"tot_def_F\",\n",
    "                        \"plaintiff_M_y\": \"tot_plain_M\",\n",
    "                        \"plaintiff_F_y\": \"tot_plain_F\",\n",
    "                        \"other_M_y\": \"tot_other_M\",\n",
    "                        \"other_F_y\": \"tot_other_F\",\n",
    "                        \"male_y\": \"tot_M\",\n",
    "                        \"female_y\": \"tot_F\",\n",
    "                        \"total_y\": \"tot\"\n",
    "                               })\n",
    "\n",
    "df_att[\"firm\"] = df_att[\"firm\"].str.title()\n",
    "names[\"name\"] = names[\"name\"].str.title()\n",
    "\n",
    "for extra in [\"Llc\", \" L.L.C.\", \" Co \", \"Company\", \"Corporation\", \"Co.\", \"Inc.\", \"Incorporated\", \"Corp.\"]:\n",
    "    df_att[\"firm\"] = df_att[\"firm\"].str.replace(extra, \"\")\n",
    "    names[\"name\"] = names[\"name\"].str.replace(extra, \"\")\n",
    "    \n",
    "df_att[\"firm\"] = df_att[\"firm\"].str.strip(\",. \")\n",
    "names[\"name\"] = names[\"name\"].str.strip(\",. \")\n",
    "\n",
    "# names.drop(columns=[\"case_number\", \"party_row_count\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7712b81-41f9-4a02-a36d-e3eadd8ac0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge name and df on party/firm to create a dataset of inhouse attorneys\n",
    "df_inhouse = df_att.merge(names, left_on=[\"firm\", \"case_row_id\"], right_on=[\"name\",\"case_row_id\"], how=\"inner\")\n",
    "\n",
    "list(df_inhouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc31556d-8917-48f9-a6b7-166d3f1a07c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse dataset by attorney, party_row_count\n",
    "df_inhouse = df_inhouse.groupby([\"name_attorney\", \"party_row_count\", \"case_row_id\"]).agg(\"first\")\n",
    "\n",
    "df_inhouse.reset_index(inplace=True)\n",
    "# df_inhouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec068ab-9f27-41d0-9c73-b0e14258e574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inhouse[df_inhouse[\"gender\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed3fe67-ab11-43e1-8b3f-c75b67d9fffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_inhouse[[\"name_attorney\", \"firm\", \"name\", \"case_name\"]].sample(n=100)\n",
    "df_inhouse.to_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/inhouse_attorneys.csv\",index = False)\n",
    "df_att.to_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/attorneys_merged.csv\",index = False)\n",
    "df_cases.to_csv(\"C://Users/schwa/OneDrive/Desktop/School/ECO225/Data/cases_merged.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862cb803-bc2c-4801-8ce0-9ad0d580e8d5",
   "metadata": {},
   "source": [
    "## Creating summary statistics and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a131e6b4-c37f-4967-8f02-bb2643167fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inhouse.describe().apply(lambda s: s.apply('{0:.5f}'.format))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9de74-8bf4-4864-bf2a-c24497afaf20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### figures/summary stats for understanding the dataset\n",
    "\n",
    "# general summary statistics for numeric variables\n",
    "summary_numeric = grouped_cases[[\"year_filed\", \"demand_num\"]].describe()\n",
    "print(summary_numeric)\n",
    "\n",
    "# create crosstab of jury demand\n",
    "freq_jury = grouped_cases[\"jury_demand\"].value_counts()\n",
    "print(freq_jury)\n",
    "                        \n",
    "# create a histogram of filing over time\n",
    "plt.hist(m_cases[\"year_filed\"], bins=30, color='skyblue', edgecolor='black')\n",
    "# Adding labels and title\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of case filing years') \n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "# create a bar chart of the distribution of cases across year by most filed in states\n",
    "most_filed_states_id = m_cases[\"court_state\"].value_counts().nlargest(5).index\n",
    "most_filed_states = m_cases.loc[m_cases[\"court_state\"].isin(most_filed_states_id), :]\n",
    "list(most_filed_states[\"court_state\"].unique())\n",
    "sns.set()\n",
    "ax = sns.countplot(data=most_filed_states, x='post_99', hue='court_state')\n",
    "ax.set_xlabel('Pre versus post 1999') \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa5634e-0fb4-45dd-8220-09ac1108e8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16a833-0093-49d1-9038-906d14513679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of the number of documents filed per case\n",
    "df_hist = df[df[\"number_docs\"] < df[\"number_docs\"].quantile(0.95)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "df_hist.plot(\n",
    "    kind=\"hist\", y=\"number_docs\",\n",
    "    bins=20, legend=False, density=True, ax=ax, edgecolor = \"black\"\n",
    ")\n",
    "ax.set_facecolor((0.96, 0.96, 0.96))\n",
    "fig.set_facecolor((0.96, 0.96, 0.96))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_title(\"Distribution of documents filed per US patent case, 1999-2015\")\n",
    "plt.savefig(\"C:/Users/schwa/OneDrive/Desktop/School/ECO225/Results/histogram_doc_filings.png\", dpi=300, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbd74d-0117-4fac-8c40-2088b8f0ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "### bar chart of % of lawyers who are women by party type\n",
    "\n",
    "# collapse dataset over year ranges\n",
    "df_year = df.drop(df.iloc[:, 0:14], axis=1)\n",
    "df_year = df_year.drop([\"date_filed\",\t\"date_closed\", \"date_last_filed\"], axis=1)\n",
    "df_year.loc[df_year[\"year_filed\"] <= 2005, \"year_range\"] = \"1999-2005\"\n",
    "df_year.loc[(2006 <= df_year[\"year_filed\"]) & (df_year[\"year_filed\"] <= 2010), \"year_range\"] = \"2006-2010\"\n",
    "df_year.loc[df_year[\"year_filed\"] >= 2011, \"year_range\"] = \"2011-2015\"\n",
    "df_year = df_year.groupby(\"year_range\").agg(\"sum\")\n",
    "df_year = df_year.reset_index()\n",
    "\n",
    "# create variables with proportion of female attorneys for each party type\n",
    "df_year[\"percent_f\"] = 100 * df_year[\"female\"] / (df_year[\"female\"] + df_year[\"male\"])\n",
    "df_year[\"percent_pl_f\"] = 100 * df_year[\"plaintiff_F\"] / (df_year[\"plaintiff_F\"] + df_year[\"plaintiff_M\"])\n",
    "df_year[\"percent_def_f\"] = 100 * df_year[\"defendant_F\"] / (df_year[\"defendant_F\"] + df_year[\"defendant_M\"])\n",
    "# df_year[\"percent_other_f\"] = 100 * df_year[\"other_F\"] / (df_year[\"other_F\"] + df_year[\"other_M\"])\n",
    "\n",
    "df_year = df_year.drop(df_year.iloc[:, 1:28], axis=1)\n",
    "\n",
    "# df_year.plot(x=\"year_range\", kind=\"bar\", stacked=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab898b8-a6df-4348-b0d8-0272b26fd348",
   "metadata": {},
   "outputs": [],
   "source": [
    "Row_list =[]\n",
    "\n",
    "# iterate over each row\n",
    "for index, rows in df_year.iterrows():\n",
    "    # Create list for the current row\n",
    "    my_list =[rows.percent_f, rows.percent_def_f, rows.percent_pl_f]\n",
    "    \n",
    "    # append the list to the final list\n",
    "    Row_list.append(my_list)\n",
    "\n",
    "print(Row_list)\n",
    "df_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393d4990-b3c2-4ef4-ae30-da4366cfe301",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"All\", \"Plaintiff\", \"Defendant\"]\n",
    "\n",
    "Row_list =[]\n",
    "\n",
    "# iterate over each row\n",
    "for index, rows in df_year.iterrows():\n",
    "    # Create list for the current row\n",
    "    my_list =[rows.percent_f, rows.percent_def_f, rows.percent_pl_f]\n",
    "    # append the list to the final list\n",
    "    Row_list.append(my_list)\n",
    "\n",
    "range_1 = Row_list[0]\n",
    "range_2 = Row_list[1]\n",
    "range_3 = Row_list[2]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "index = np.arange(3)\n",
    "width = 0.2\n",
    "\n",
    "rects1 = ax.bar(\n",
    "    index, range_1, width, label='All', edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "rects2 = ax.bar(\n",
    "    index + width, range_2, width, label='Plaintiff', edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "rects3 = ax.bar(\n",
    "    index + width*2, range_3, width, label='Defendant', edgecolor=\"black\"\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Percent of female attorneys')\n",
    "ax.set_title('Gender make-up of patent attorneys litigating in US district courts, 1999-2015')\n",
    "ax.set_xticks(index + width )\n",
    "ax.set_xticklabels(('1999-2005', '2006-2010', '2011-2015'))\n",
    "ax.legend()\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"C:/Users/schwa/OneDrive/Desktop/School/ECO225/Results/bar_attorney_gender.png\", dpi=300, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e5a66c-f7c0-47f8-aa15-f967c74de59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### relationship between the proportion of court filings and the proportion of lawyers in a court who a women\n",
    "\n",
    "df_court = df.drop([\"date_filed\", \"date_closed\", \"date_last_filed\"], axis=1)\n",
    "df_court.loc[df_court[\"year_filed\"] <= 2005, \"year_range\"] = \"1999-2005\"\n",
    "df_court.loc[(2006 <= df_court[\"year_filed\"]) & (df_court[\"year_filed\"] <= 2010), \"year_range\"] = \"2006-2010\"\n",
    "df_court.loc[df_court[\"year_filed\"] >= 2011, \"year_range\"] = \"2011-2015\"\n",
    "df_court = df_court.groupby([\"court_state\", \"court_region\", \"year_range\"]).agg(\"sum\")\n",
    "df_court = df_court.reset_index()\n",
    "\n",
    "# create variable showing proportion of case filings made in year range in a given court\n",
    "df_court.loc[df_court[\"year_range\"] == \"1999-2005\", \"total_filings\"] = df_court[df_court[\"year_range\"] == \"1999-2005\"][\"post_99\"].sum(axis=0)\n",
    "df_court.loc[df_court[\"year_range\"] == \"2006-2010\", \"total_filings\"] = df_court[df_court[\"year_range\"] == \"2006-2010\"][\"post_99\"].sum(axis=0)\n",
    "df_court.loc[df_court[\"year_range\"] == \"2011-2015\", \"total_filings\"] = df_court[df_court[\"year_range\"] == \"2011-2015\"][\"post_99\"].sum(axis=0)\n",
    "df_court[\"percent_filings\"] = 100* df_court[\"post_99\"] / df_court[\"total_filings\"] \n",
    "\n",
    "df_court[\"percent_female\"] = 100 * df_court[\"female\"] / (df_court[\"female\"] + df_court[\"male\"])\n",
    "\n",
    "df_court.head(10)\n",
    "df_court.loc[df_court[\"percent_female\"].isna(), \"percent_female\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f8b48a-76f4-4986-8d04-c00c39b521cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def single_scatter_plot(df, year, ax):\n",
    "    \"\"\"\n",
    "    This function creates a single year's percent filings to percent female plot\n",
    "    \"\"\"\n",
    "    # Filter data to keep only the data of interest\n",
    "    _df = df_court[df_court['year_range'] == year]\n",
    "    _df.plot(\n",
    "        kind=\"scatter\", x=\"percent_filings\", y=\"percent_female\", ax=ax\n",
    "    )\n",
    "\n",
    "    lr = LinearRegression()\n",
    "    X = _df[\"percent_filings\"].values.reshape(-1, 1)# you can feed -1 as one of the values in reshape and \n",
    "                                                # let numpy figure out that dimension\n",
    "    y = _df[\"percent_female\"].values.reshape(-1, 1) # the output is an array\n",
    "    lr.fit(X, y)\n",
    "\n",
    "    x = np.linspace(2.0, 12.0).reshape(-1, 1)\n",
    "    y_pred = lr.predict(x)\n",
    "    ax.plot(x, y_pred)\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Create initial plot\n",
    "fig, ax = plt.subplots(1, 3, figsize=(16, 6))\n",
    "\n",
    "for (i, year) in enumerate(df_court.year_range.unique()):\n",
    "    single_scatter_plot(df, year, ax[i])\n",
    "    ax[i].set_title(str(year))\n",
    "\n",
    "bgcolor = (250/255, 250/255, 250/255)\n",
    "fig.set_facecolor(bgcolor)\n",
    "for (i, _ax) in enumerate(ax):\n",
    "    # Label with words\n",
    "    if i == 0:\n",
    "        _ax.set_xlabel(\"Percent of all patent cases filed in the district\")\n",
    "    else:\n",
    "        _ax.set_xlabel(\"\")\n",
    "\n",
    "    # Turn off right and top axis lines\n",
    "    _ax.spines['right'].set_visible(False)\n",
    "    _ax.spines['top'].set_visible(False)\n",
    "\n",
    "    # Don't use such a white background color\n",
    "    _ax.set_facecolor(bgcolor)\n",
    "\n",
    "    # Change bounds\n",
    "    _ax.set_ylim((0, 50))\n",
    "    _ax.set_xlim((-0.2, 20))\n",
    " \n",
    "    # Change ticks\n",
    "    # xticks = [10, 100, 1000, 10000]\n",
    "    # _ax.set_xticks([np.log(xi) for xi in xticks])\n",
    "    # _ax.set_xticklabels([str(xi) for xi in xticks])\n",
    "\n",
    "    # yticks = list(range(5, 32, 5))\n",
    "    # _ax.set_yticks([np.log(yi) for yi in yticks])\n",
    "    if i == 0:\n",
    "        # _ax.set_yticklabels([str(yi) for yi in yticks])\n",
    "        _ax.set_ylabel(\"Percent female attorneys listed on cases filed\")\n",
    "    else:\n",
    "        # _ax.set_yticklabels([])\n",
    "        _ax.set_ylabel(\"\")\n",
    "\n",
    "ax[0].set_zorder(1)\n",
    "fig.suptitle(\"US federal courts' patent filings and the gender make-up of attorneys\")\n",
    "plt.savefig(\"C:/Users/schwa/OneDrive/Desktop/School/ECO225/Results/scatter_filings_gender.png\", dpi=300, format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954ddc86-d880-43bc-acd7-c05fd4a16611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent filings in top 10 courts by year\n",
    "\n",
    "df_top = df.drop([\"date_filed\", \"date_closed\", \"date_last_filed\"], axis=1)\n",
    "df_top = df_top.groupby([\"court_state\", \"court_region\", \"year_filed\"]).agg(\"sum\")\n",
    "df_top = df_top.reset_index()\n",
    "df_top = df_top.drop(df_top.iloc[:, 3:22], axis=1)\n",
    "\n",
    "# create variable showing proportion of case filings made in year range in a given court\n",
    "for year in range(1999, 2016):\n",
    "    df_top.loc[df_top[\"year_filed\"] == year, \"total_filings\"] = df_top[df_top[\"year_filed\"] == year][\"post_99\"].sum(axis=0)\n",
    "\n",
    "# create new dataset with top 10 courts, bottom 10 courts\n",
    "df_top_years = df_top[df_top[\"year_filed\"] == 1999].nlargest(10, \"post_99\")\n",
    "for year in range(2000, 2016):\n",
    "    _df = df_top[df_top[\"year_filed\"] == year].nlargest(10, \"post_99\")\n",
    "    df_top_years = pd.concat([df_top_years, _df], axis = 0)\n",
    "df_top_years[\"top10\"] = 1\n",
    "\n",
    "for year in range(1999, 2016):\n",
    "    _df = df_top[df_top[\"year_filed\"] == year].nsmallest(84, \"post_99\")\n",
    "    df_top_years = pd.concat([df_top_years, _df], axis = 0)\n",
    "df_top_years = df_top_years.fillna(0)\n",
    "\n",
    "df_top_years = df_top_years.drop(df_top_years.iloc[:, 4:23], axis=1)\n",
    "df_top_years = df_top_years.drop(df_top_years.iloc[:, 0:2], axis=1)\n",
    "df_top_years[\"year_filed\"] = df_top_years[\"year_filed\"].astype(int)\n",
    "df_top_years = df_top_years.groupby([\"top10\", \"year_filed\"]).agg({\"post_99\":\"sum\", \"total_filings\": \"max\"})\n",
    "\n",
    "df_top_years[\"percent_filings\"] = 100* df_top_years[\"post_99\"] / df_top_years[\"total_filings\"]\n",
    "\n",
    "# df_top_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156a7a9a-3335-4eea-bb9b-43da2a1d3854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_years = df_top_years.drop([\"post_99\", \"total_filings\"], axis=1)\n",
    "df_top_years = df_top_years.reset_index(level = \"top10\")\n",
    "df_top_years = df_top_years[df_top_years[\"top10\"] == 1]\n",
    "df_top_years = df_top_years.drop(\"top10\", axis=1)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_top_years[\"percent_filings\"].plot(kind=\"bar\", ax=ax, color=\"#1b42fc\")\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(\"Percent filings in 10 most filed in district courts\")\n",
    "ax.set_title(\"Patent cases filed in most filed in US district circuits, 1999-2015\")\n",
    "plt.savefig(\"C:/Users/schwa/OneDrive/Desktop/School/ECO225/Results/bar_top10.png\", dpi=200, format=\"png\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
